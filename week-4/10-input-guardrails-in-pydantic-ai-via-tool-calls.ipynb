{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e270d12e",
   "metadata": {},
   "source": [
    "# Input Guardrails in Pydantic AI via Tool Calls\n",
    "\n",
    "We implemented input guardrails with OpenAI Agents SDK in the previous lesson.\n",
    "\n",
    "Now we will do the same with PydanticAI.\n",
    "\n",
    "PydanticAI does not have built-in guardrail functionality like Agents SDK.\n",
    "\n",
    "We need to implement it ourselves.\n",
    "\n",
    "There is an open issue that discusses guardrails implementation: https://github.com/pydantic/pydantic-ai/issues/1197\n",
    "\n",
    "The issue describes two approaches for implementing guardrails:\n",
    "\n",
    "- Using a tool call to validate input\n",
    "- Running validation in parallel like Agents SDK does\n",
    "\n",
    "The tool call approach is simpler to implement.\n",
    "\n",
    "We will start with that approach.\n",
    "\n",
    "## Defining the Guardrail Output Model\n",
    "\n",
    "Create the output model for the guardrail decision. (`guardrails-pydantic-ai/search_agent.py`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb065eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvidentlyDocsGuardrail(BaseModel):\n",
    "    resoning: str\n",
    "    fail: bool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db3e57",
   "metadata": {},
   "source": [
    "## Implementing the Guardrail Tool\n",
    "\n",
    "Create a tool function that checks for prohibited topics.\n",
    "\n",
    "The agent will call this tool to validate user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9efe5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_guardrail(message: str) -> EvidentlyDocsGuardrail:\n",
    "    \"\"\"\n",
    "    This function checks if the user message contains prohibited topics.\n",
    "    Args:\n",
    "        message: The user input message\n",
    "    Returns:\n",
    "        EvidentlyDocsGuardrail indicating if tripwire was triggered           \n",
    "    \"\"\"\n",
    "    prohibited_topics = [\n",
    "        \"sqrt\", \"math\", \"history\"\n",
    "    ]\n",
    "\n",
    "    for topic in prohibited_topics:\n",
    "        if topic in message.lower():\n",
    "            return EvidentlyDocsGuardrail(\n",
    "                reasoning=f'Input contains prohibited topic: {topic}',\n",
    "                fail=True\n",
    "            )\n",
    "\n",
    "    return EvidentlyDocsGuardrail(\n",
    "        reasoning='Input is clean',\n",
    "        fail=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50036dc",
   "metadata": {},
   "source": [
    "## Adding the Guardrail to the Agent\n",
    "\n",
    "Add the guardrail function to the agent tools list.\n",
    "\n",
    "The agent will now have access to the guardrail as a callable tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"search\",\n",
    "    instructions=search_instructions,\n",
    "    tools=[\n",
    "        tools.search,\n",
    "        tools.read_file,\n",
    "        input_guardrail\n",
    "    ],\n",
    "    model=config.model,\n",
    "    output_type=SearchResultArticle,\n",
    "    history_processors=[force_answer_after_6_searches]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9893f08",
   "metadata": {},
   "source": [
    "## Testing the Guardrail\n",
    "\n",
    "Run the agent with an input that contains a prohibited topic.\n",
    "\n",
    "The agent should call the guardrail tool and detect the violation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49742a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await run_stream(agent, 'how much is sqrt(pi)', SearchResultHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64162cd",
   "metadata": {},
   "source": [
    "## Limitations and Next Steps\n",
    "\n",
    "This approach is simple and works well.\n",
    "\n",
    "However, it adds to the execution time because the guardrail runs as a tool call. Also, the agent needs to decide to call the guardrail tool first - and this is not guaranteed.\n",
    "\n",
    "In the next lesson we will implement parallel guardrails."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
