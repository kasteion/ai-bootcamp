{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6863fa3b",
   "metadata": {},
   "source": [
    "# Collecting Agent Logs for Monitoring\n",
    "\n",
    "We have the working application so let's now start collecting logs.\n",
    "\n",
    "First we will do this manually but later we will see how to do it with special software."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b599d",
   "metadata": {},
   "source": [
    "## Log Storage Strategy\n",
    "\n",
    "We can imagine that these logs are saved to kafka or some logs collection system (logstash, fluentd, etc).\n",
    "\n",
    "But here for simplicity we will put them in a file system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881c813",
   "metadata": {},
   "source": [
    "## Creating Log Entries\n",
    "\n",
    "Create `agent_logging.py`\n",
    "\n",
    "Let's capture all the important information and create `create_log_entry`.\n",
    "\n",
    "This function extracts all the essential information: agent configuration, tool usage, conversation history, token usage, and final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e677308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pydantic\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.usage import RunUsage\n",
    "from pydantic_ai.messages import ModelMessage\n",
    "\n",
    "from pydantic_ai.messages import ModelMessagesTypeAdapter\n",
    "\n",
    "\n",
    "UsageTypeAdapter = pydantic.TypeAdapter(RunUsage)\n",
    "\n",
    "\n",
    "def create_log_entry(\n",
    "    agent: Agent,\n",
    "    messages: List[ModelMessage],\n",
    "    usage: RunUsage,\n",
    "    output: str\n",
    "):\n",
    "    tools = []\n",
    "\n",
    "    for ts in agent.toolsets:\n",
    "        tools.extend(ts.tools.keys())\n",
    "\n",
    "    dict_messages = ModelMessagesTypeAdapter.dump_python(messages)\n",
    "    dict_usage = UsageTypeAdapter.dump_python(usage)\n",
    "\n",
    "    return {\n",
    "        \"agent_name\": agent.name,\n",
    "        \"system_prompt\": agent._instructions,\n",
    "        \"provider\": agent.model.system,\n",
    "        \"model\": agent.model.model_name,\n",
    "        \"tools\": tools,\n",
    "        \"messages\": dict_messages,\n",
    "        \"usage\": dict_usage,\n",
    "        \"output\": output,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366530be",
   "metadata": {},
   "source": [
    "It creates a log entry - a dictionary that later can easilty be serialized into JSON.\n",
    "\n",
    "For conversions we use type adapters from Pydantic - to convert dataclasses to dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd80b7f1",
   "metadata": {},
   "source": [
    "## Handling Different Run Types\n",
    "\n",
    "We need separate functions for streamed and regular runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.run import AgentRunResult\n",
    "from pydantic_ai.result import StreamedRunResult\n",
    "\n",
    "async def log_streamed_run(\n",
    "    agent: Agent,\n",
    "    result: StreamedRunResult\n",
    "):\n",
    "    output = await result.get_output()\n",
    "    usage = result.usage()\n",
    "    messages = result.all_messages()\n",
    "\n",
    "    log = create_log_entry(\n",
    "        agent=agent,\n",
    "        messages=messages,\n",
    "        usage=usage,\n",
    "        output=output\n",
    "    )\n",
    "\n",
    "    return log\n",
    "\n",
    "\n",
    "def log_run(\n",
    "    agent: Agent,\n",
    "    result: AgentRunResult\n",
    "):\n",
    "    output = result.output\n",
    "    usage = result.usage()\n",
    "    messages = result.all_messages()\n",
    "\n",
    "    log = create_log_entry(\n",
    "        agent=agent,\n",
    "        messages=messages,\n",
    "        usage=usage,\n",
    "        output=output\n",
    "    )\n",
    "\n",
    "    return log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71429e2",
   "metadata": {},
   "source": [
    "The key difference is that streamed runs require awaiting the final output, while regular runs have it immediately available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3430bec",
   "metadata": {},
   "source": [
    "## Saving Logs to Filesystem\n",
    "\n",
    "Finally, we save it to a JSON file.\n",
    "\n",
    "For that, we first need custom serialization for complex objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "\n",
    "def serializer(obj):\n",
    "    if isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "    if isinstance(obj, BaseModel):\n",
    "        return obj.model_dump()\n",
    "    raise TypeError(f\"Type {type(obj)} not serializable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50baecc3",
   "metadata": {},
   "source": [
    "And a helper function to extract the timestamp from the logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027fd404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_last_timestamp(messages):\n",
    "    for msg in reversed(messages):\n",
    "        if 'timestamp' in msg:\n",
    "            return msg['timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785c7524",
   "metadata": {},
   "source": [
    "Now save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import secrets\n",
    "from pathlib import Path\n",
    "\n",
    "def save_log(entry: dict):\n",
    "    logs_folder = Path('logs')\n",
    "    logs_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    ts = find_last_timestamp(entry['messages'])\n",
    "    ts_str = ts.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    rand_hex = secrets.token_hex(3)\n",
    "\n",
    "    agent_name = entry['agent_name'].replace(\" \", \"_\").lower()\n",
    "\n",
    "    filename = f\"{agent_name}_{ts_str}_{rand_hex}.json\"\n",
    "    filepath = logs_folder / filename\n",
    "\n",
    "    with filepath.open(\"w\", encoding=\"utf-8\") as f_out:\n",
    "        json.dump(entry, f_out, indent=2, default=serializer)\n",
    "\n",
    "    return filepath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91183753",
   "metadata": {},
   "source": [
    "This creates unique filenames combining agent name, timestamp, and random hex to prevent conflicts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d98878",
   "metadata": {},
   "source": [
    "## Integrating with Your Application\n",
    "\n",
    "Include it in your app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfe27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_entry = await log_streamed_run(agent, result)\n",
    "log_file = save_log(log_entry)\n",
    "print(f\"\\n\\nLog saved to: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b9277c",
   "metadata": {},
   "source": [
    "Now every agent interaction is automatically logged with complete context for monitoring and analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
