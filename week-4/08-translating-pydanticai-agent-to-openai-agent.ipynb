{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fa8e0e",
   "metadata": {},
   "source": [
    "# Translating PydanticAI Agent to OpenAI Agents SDK\n",
    "\n",
    "We will illustrate the concept of guardrails with OpenAI Agents SDK because it has built-in support. With Pydantic AI we need to implement guardrails ourselves. We will do that later.\n",
    "\n",
    "First we will translate the agent we created so far into Agents SDK.\n",
    "\n",
    "This will prepare us for implementing guardrails in the next step.\n",
    "\n",
    "If you want to skip this video, you can find the complete code here: https://github.com/alexeygrigorev/ai-bootcamp-codespace/tree/main/week4/guardrails-agents-sdk.\n",
    "\n",
    "## Setting Up the Agent\n",
    "\n",
    "We will reuse the documentation and search tools from our previous PydanticAI implementation.\n",
    "\n",
    "Copy the docs and `search_tools` modules from the previous agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45488a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docs\n",
    "import search_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489a548",
   "metadata": {},
   "source": [
    "We also need to import the dataclasses and Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cadea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d8970f",
   "metadata": {},
   "source": [
    "Now copy things from the `search_agent` module:\n",
    "\n",
    "First, the agent configuration with chunk sizes and model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfccb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AgentConfig:\n",
    "    chunk_size: int = 2000\n",
    "    chunk_step: int = 1000\n",
    "    top_k: int = 5\n",
    "\n",
    "    model: str = \"gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40f420",
   "metadata": {},
   "source": [
    "Next, the instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e116f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_instructions = \"\"\"\n",
    "You are a search assistant for the Evidently documentation.\n",
    "\n",
    "Evidently is an open-source Python library and cloud platform for evaluating, testing, and monitoring data and AI systems.\n",
    "It provides evaluation metrics, testing APIs, and visual reports for model and data quality.\n",
    "\n",
    "Your task is to help users find accurate, relevant information about Evidently's features, usage, and integrations.\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "- search — Use this to explore the topic and retrieve relevant snippets or documentation.\n",
    "- read_file — Use this to retrieve or verify the complete content of a file when:\n",
    "    * A code snippet is incomplete, truncated, or missing definitions.\n",
    "    * You need to check that all variables, imports, and functions referenced in code are defined.\n",
    "    * You must ensure the code example is syntactically correct and runnable.\n",
    "\n",
    "If `read_file` cannot be used or the file content is unavailable, clearly state:\n",
    "> \"Unable to verify with read_file.\"\n",
    "\n",
    "Search Strategy\n",
    "\n",
    "- For every user query:\n",
    "    * Perform at least 3 and at most 6 distinct searches to gather enough context.\n",
    "    * Each search must use a different phrasing or keyword variation of the user's question.\n",
    "    * Make sure that the search requests are relevant to evidently, testing, evaluating and monitoring AI systems.\n",
    "    * No need to include \"Evidently\" in the search text.\n",
    "\n",
    "- After collecting search results:\n",
    "    1. Synthesize the information into a concise, accurate answer.\n",
    "    2. If your answer includes code, always validate it with `read_file` before finalizing.\n",
    "    3. If a code snippet or reference is incomplete, explicitly mention it.\n",
    "\n",
    "Important:\n",
    "- The 6-search limit applies only to `search` calls.\n",
    "- You may call `read_file` at any time, even after the search limit is reached.\n",
    "- `read_file` calls are verification steps and do not count toward the 6-search limit.\n",
    "\n",
    "Code Verification and Completeness Rules\n",
    "\n",
    "- All variables, functions, and imports in your final code examples must be defined or imported.\n",
    "- Never shorten, simplify, or truncate code examples. Always present the full, verified version.\n",
    "- When something is missing or undefined in the search results:\n",
    "    * Call `read_file` with the likely filename to retrieve the complete file content.\n",
    "    * Replace any partial code with the full verified version.\n",
    "- If the file is not available or cannot be verified:\n",
    "    * Include a clear note: \"Unable to verify this code.\"\n",
    "- Do not reformat, rename variables, or omit lines from the verified code.\n",
    "\n",
    "Output Format\n",
    "\n",
    "- Write your answer clearly and accurately.\n",
    "- Include a \"References\" section listing the search queries or file names you used.\n",
    "- If you couldn't find a complete answer after 6 searches, set found_answer = False.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff74ec16",
   "metadata": {},
   "source": [
    "Finally, the output models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3be373",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reference(BaseModel):\n",
    "    title: str\n",
    "    filename: str\n",
    "\n",
    "class Section(BaseModel):\n",
    "    heading: str\n",
    "    content: str\n",
    "    references: list[Reference]\n",
    "\n",
    "class SearchResultArticle(BaseModel):\n",
    "    found_answer: bool\n",
    "    title: str\n",
    "    sections: list[Section]\n",
    "    references: list[Reference]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ffa55",
   "metadata": {},
   "source": [
    "Now we can implement the agent.\n",
    "\n",
    "## Creating the Agent\n",
    "\n",
    "Initialize the configuration and prepare the search tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c9ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AgentConfig()\n",
    "\n",
    "tools = search_tools.prepare_search_tools(\n",
    "    config.chunk_size,\n",
    "    config.chunk_step,\n",
    "    config.top_k\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7995dc",
   "metadata": {},
   "source": [
    "Create the agent with the tools and instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, function_tool\n",
    "\n",
    "agent_tools = [\n",
    "    function_tool(tools.search),\n",
    "    function_tool(tools.read_file)\n",
    "]\n",
    "\n",
    "search_agent = Agent(\n",
    "    name='search',\n",
    "    tools=agent_tools,\n",
    "    instructions=search_instructions,\n",
    "    model=config.model,\n",
    "    output_type=SearchResultArticle,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c6f7c",
   "metadata": {},
   "source": [
    "## Running the Agent\n",
    "\n",
    "Run the agent with a simple query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460122c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "\n",
    "input = 'llm as a judge'\n",
    "result = await Runner.run(search_agent, input=input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b0275b",
   "metadata": {},
   "source": [
    "## Streaming the Response\n",
    "\n",
    "We can stream the agent response to see tool calls and output in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bf683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "\n",
    "result = Runner.run_streamed(\n",
    "    search_agent,\n",
    "    input=input,\n",
    ")\n",
    "\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"run_item_stream_event\":\n",
    "        if event.item.type == \"tool_call_item\":\n",
    "            tool_call = event.item.raw_item\n",
    "            f_name = tool_call.name\n",
    "            args = tool_call.arguments\n",
    "            print(f\"TOOL CALL ({event.item.agent.name}): {f_name}({args})\")\n",
    "    \n",
    "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5117ffd4",
   "metadata": {},
   "source": [
    "## Parsing Structured Output\n",
    "\n",
    "Like previously, we can parse the JSON output incrementally as it streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ea68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxn import StreamingJSONParser, JSONParserHandler\n",
    "\n",
    "class SearchResultHandler(JSONParserHandler):\n",
    "    def on_field_start(self, path: str, field_name: str):\n",
    "        if field_name == \"references\":\n",
    "            level = path.count(\"/\") + 2\n",
    "            print(f\"\\n{'#' * level} References\\n\")\n",
    "\n",
    "    def on_field_end(self, path, field_name, value, parsed_value=None):\n",
    "        if field_name == \"title\" and path == \"\":\n",
    "            print(f\"# {value}\")\n",
    "\n",
    "        elif field_name == \"heading\":\n",
    "            print(f\"\\n\\n## {value}\\n\")\n",
    "        elif field_name == \"content\":\n",
    "            print(\"\\n\") \n",
    "\n",
    "    def on_value_chunk(self, path, field_name, chunk):\n",
    "        if field_name == \"content\":\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "\n",
    "    def on_array_item_end(self, path, field_name, item=None):\n",
    "        if field_name == \"references\":\n",
    "            title = item.get(\"title\", \"\")\n",
    "            filename = item.get(\"filename\", \"\")\n",
    "            print(f\"- [{title}]({filename})\")\n",
    "\n",
    "handler = SearchResultHandler()\n",
    "parser = StreamingJSONParser(handler)\n",
    "\n",
    "# Parse each chunk as it arrives\n",
    "parser.parse_incremental(event.data.delta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38804e",
   "metadata": {},
   "source": [
    "## Handling Too Many Tool Calls\n",
    "\n",
    "The agent might exceed the maximum number of tool calls. In PydanticAI we used `history_processors` for that.\n",
    "\n",
    "In Agents SDK we have a little less flexibility, but we can count the number of iterations of the loop, and break the execution when it exceeds the limit.\n",
    "\n",
    "We do it by setting the `max_turns` parameter. This is how we can do it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.exceptions import MaxTurnsExceeded\n",
    "\n",
    "try:\n",
    "    # Run the agent\n",
    "    result = Runner.run_streamed(\n",
    "        search_agent,\n",
    "        input=input,\n",
    "        max_turns=3\n",
    "    )\n",
    "\n",
    "    ...\n",
    "except MaxTurnsExceeded as e:\n",
    "    print('too many turns')\n",
    "    finish_prompt = 'System message: The number of searches has exceeded the limit. Proceed to finishing the writeup'\n",
    "    finish_message = [{'role': 'user', 'content': finish_prompt}]\n",
    "    messages = result.to_input_list() + finish_message\n",
    "    # Run one more time with the accumulated messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720054fc",
   "metadata": {},
   "source": [
    "## Complete Streaming Function\n",
    "\n",
    "Here is the complete function that handles streaming and turn limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a81751",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_stream(agent, input, handler, max_turns=3):\n",
    "    try:\n",
    "        result = Runner.run_streamed(\n",
    "            agent,\n",
    "            input=input,\n",
    "            max_turns=max_turns\n",
    "        )\n",
    "        \n",
    "        parser = StreamingJSONParser(handler)\n",
    "\n",
    "        async for event in result.stream_events():\n",
    "            if event.type == \"run_item_stream_event\":\n",
    "                if event.item.type == \"tool_call_item\":\n",
    "                    tool_call = event.item.raw_item\n",
    "                    f_name = tool_call.name\n",
    "                    args = tool_call.arguments\n",
    "                    print(f\"TOOL CALL ({event.item.agent.name}): {f_name}({args})\")\n",
    "            \n",
    "            if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "                parser.parse_incremental(event.data.delta)\n",
    "\n",
    "        return result\n",
    "    except MaxTurnsExceeded as e:\n",
    "        print('too many turns')\n",
    "        finish_prompt = 'System message: The number of searches has exceeded the limit. Proceed to finishing the writeup'\n",
    "        finish_message = [{'role': 'user', 'content': finish_prompt}]\n",
    "        messages = result.to_input_list() + finish_message\n",
    "        final_result = await run_stream(agent, input=messages, handler=handler, max_turns=1)\n",
    "        return final_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298c533",
   "metadata": {},
   "source": [
    "Let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await run_stream(search_agent, 'llm as a judge', SearchResultHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e99825",
   "metadata": {},
   "source": [
    "Now we're ready to add guardrails to this code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
