{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d8a162b",
   "metadata": {},
   "source": [
    "# Preparation: Streamlit UI and Streaming Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08efd375",
   "metadata": {},
   "source": [
    "[code](https://github.com/alexeygrigorev/ai-bootcamp-codespace/tree/main/week4/code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12d465",
   "metadata": {},
   "source": [
    "## Current Application Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd459f8b",
   "metadata": {},
   "source": [
    "This is our application so far:\n",
    "\n",
    "`ver1.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import search_agent\n",
    "\n",
    "async def main():\n",
    "    user_input = \"How do I monitor data drift in production?\"\n",
    "\n",
    "    agent = search_agent.create_agent()\n",
    "    callback = search_agent.NamedCallback(agent)\n",
    "\n",
    "    result = await agent.run(user_input, event_stream_handler=callback)\n",
    "    article = result.output\n",
    "\n",
    "    print(article.format_article())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585298b",
   "metadata": {},
   "source": [
    "Here the user is waiting for the agento to finish before seeing any result. We want to add streaming of the output to have a better user experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961bd30",
   "metadata": {},
   "source": [
    "## The Streaming Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156248da",
   "metadata": {},
   "source": [
    "We want the application to stream output instead of waiting for the agent to finish working.\n",
    "\n",
    "The problem: we have structured output, so it's not as simple as streaming text. The output is JSON.\n",
    "\n",
    "Let's implement streaming using PydanticAI's streaming capabilites. In PydanticAI, structured output hapens via a fictional tool call, so we need to detect when this tool is invoked.\n",
    "\n",
    "`ver2.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de888716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import search_agent\n",
    "\n",
    "async def main():\n",
    "    user_input = \"How do I monitor data drift in production?\"\n",
    "\n",
    "    agent = search_agent.create_agent()\n",
    "    callback = search_agent.NamedCallback(agent)\n",
    "\n",
    "    previous_text = \"\"\n",
    "\n",
    "    async with agent.run_stream(\n",
    "        user_input, event_stream_handler=callback\n",
    "    ) as result:\n",
    "        async for item, last in result.stream_responses(debounce_by=0.01):\n",
    "            for part in item.parts:\n",
    "                if not hasattr(part, \"tool_name\"):\n",
    "                    continue\n",
    "                if part.tool_name != \"final_result\":\n",
    "                    continue\n",
    "\n",
    "                current_text = part.args\n",
    "                delta = current_text[len(previous_text):]\n",
    "                print(delta, end=\"\", flush=True)\n",
    "                previous_text = current_text\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a906ea1",
   "metadata": {},
   "source": [
    "This shows JSON, which is not very useful (yet), but we'll deal with it later.\n",
    "\n",
    "If you want to get the final output this is how you do it (after the loop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f045cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = await result.get_output()\n",
    "print(article.format_article())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a470f",
   "metadata": {},
   "source": [
    "We can also get the messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed170e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_messages = result.new_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d42ef5",
   "metadata": {},
   "source": [
    "## Incremental JSON Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2488532a",
   "metadata": {},
   "source": [
    "Now we can see the JSON as it comes in, but it's not very useful for the user. We need to parse the JSON as it arrives.\n",
    "\n",
    "For that we can use a streaming JSON parser. For example, [JAXN](https://github.com/alexeygrigorev/jaxn). Alternatively you can use [streaming-json-parser](https://pypi.org/project/streaming-json-parser/) (which uses a different approach for parsing) or find some other implementation.\n",
    "\n",
    "JAXN implements the same idea as SAX parsers for XML: you have a stream of incoming data, and as you process it, you get the data from the callbacks that react to the current state.\n",
    "\n",
    "Let's install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb564947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m263 packages\u001b[0m \u001b[2min 1.25s\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`transformers==4.57.0` is yanked (reason: \"Error in the setup causing installation issues\")\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe package `pydantic-ai==1.1.0` does not have an extra named `mcp`\u001b[0m\n",
      "\u001b[2K\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`transformers==4.57.0` is yanked (reason: \"Error in the setup causing installation issues\")\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe package `pydantic-ai==1.1.0` does not have an extra named `mcp`\u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m     0 B/4.63 KiB            \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------\u001b[2m\u001b[0m\u001b[0m 4.63 KiB/4.63 KiB           \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 176ms\u001b[0m\u001b[0m                                                  \u001b[1A\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m                                  \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjaxn\u001b[0m\u001b[2m==0.0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add jaxn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55692d3",
   "metadata": {},
   "source": [
    "Import the necessary components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxn import StreamingJSONParser, JSONParserHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff8937f",
   "metadata": {},
   "source": [
    "You need the parser and the handler. The handler reacts to the current state in the parser, so we will use it for displaying the results.\n",
    "\n",
    "We need to implement the methods for the handler. Here are the key callback methods:\n",
    "\n",
    "on_field_start: Called when starting to read a field value\n",
    "\n",
    "on_field_end: Called when a field value is complete\n",
    "\n",
    "on_value_chunk: Called for each character as string values stream in\n",
    "\n",
    "on_array_item_start: Called when starting a new object in an array\n",
    "\n",
    "on_array_item_end: Called when finishing an object in an array\n",
    "\n",
    "Our strategy:\n",
    "\n",
    "Display title and section headers inside on_field_end\n",
    "\n",
    "Display references in on_array_item_end\n",
    "\n",
    "Display the content in a streaming way (print as it arrives)\n",
    "\n",
    "Let's create the handler:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8599452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchResultArticleHandler(JSONParserHandler):\n",
    "    def on_field_start(self, path: str, field_name: str):\n",
    "        if field_name == \"references\":\n",
    "            level = path.count(\"/\") + 2\n",
    "            print(f\"\\n{'#' * level} References\\n\")\n",
    "\n",
    "    def on_field_end(self, path, field_name, value, parsed_value=None):\n",
    "        if field_name == \"title\" and path == \"\":\n",
    "            print(f\"# {value}\")\n",
    "\n",
    "        elif field_name == \"heading\":\n",
    "            print(f\"\\n\\n## {value}\\n\")\n",
    "        elif field_name == \"content\":\n",
    "            print(\"\\n\") \n",
    "\n",
    "    def on_value_chunk(self, path, field_name, chunk):\n",
    "        if field_name == \"content\":\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "\n",
    "    def on_array_item_end(self, path, field_name, item=None):\n",
    "        if field_name == \"references\":\n",
    "            title = item.get(\"title\", \"\")\n",
    "            filename = item.get(\"filename\", \"\")\n",
    "            print(f\"- [{title}]({filename})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596398ad",
   "metadata": {},
   "source": [
    "This handler formats the streaming JSON into a readable article format as the data arrives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74d951",
   "metadata": {},
   "source": [
    "## Creating the Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d039f5",
   "metadata": {},
   "source": [
    "Now we create the parser with this handler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85561af",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = SearchResultArticleHandler()\n",
    "parser = StreamingJSONParser(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a95b63",
   "metadata": {},
   "source": [
    "And use it to parse incremental updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53642d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse_incremental(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19293043",
   "metadata": {},
   "source": [
    "When we run it, we see the output appearing on the screen in a more structured way, with proper formatting and real-time updates.\n",
    "\n",
    "This is our `ver3.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec961e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from time import time\n",
    "from typing import Any, Dict\n",
    "from jaxn import JSONParserHandler, StreamingJSONParser\n",
    "\n",
    "import search_agent\n",
    "\n",
    "from agent_logging import log_streamed_run, save_log\n",
    "\n",
    "class SearchResultArticleHandler(JSONParserHandler):\n",
    "    \n",
    "    def on_field_start(self, path: str, field_name: str) -> None:\n",
    "        if field_name == \"references\":\n",
    "            header_level = path.count('/') + 2\n",
    "            print(f\"\\n\\n{'#' * header_level} References\\n\")\n",
    "    \n",
    "    def on_field_end(self, path: str, field_name: str, value: str, parsed_value: Any = None) -> None:\n",
    "        if field_name == \"title\" and path == \"\":\n",
    "            print(f\"# {value}\\n\")\n",
    "        \n",
    "        if field_name == \"heading\":\n",
    "            print(f\"\\n\\n## {value}\\n\")\n",
    "    \n",
    "    def on_value_chunk(self, path: str, field_name: str, chunk: str) -> None:\n",
    "        if field_name == \"content\":\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "    \n",
    "    def on_array_item_end(self, path: str, field_name: str, item: Dict[str, Any] = None) -> None:\n",
    "        if field_name == \"references\":\n",
    "            print(f\"- [{item['title']}]({item['filename']})\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    user_input = \"How do I monitor data drift in production?\"\n",
    "\n",
    "    agent = search_agent.create_agent()\n",
    "    callback = search_agent.NamedCallback(agent)\n",
    "\n",
    "    # result = await agent.run(user_input, event_stream_handler=callback)\n",
    "    # article = result.output\n",
    "\n",
    "    handler = SearchResultArticleHandler()\n",
    "    parser = StreamingJSONParser(handler)\n",
    "\n",
    "    previous_text = \"\"\n",
    "\n",
    "    async with agent.run_stream(\n",
    "        user_input, event_stream_handler=callback\n",
    "    ) as result:\n",
    "        async for item, last in result.stream_responses(debounce_by=0.01):\n",
    "            for part in item.parts:\n",
    "                if not hasattr(part, \"tool_name\"):\n",
    "                    continue\n",
    "                if part.tool_name != \"final_result\":\n",
    "                    continue\n",
    "\n",
    "                current_text = part.args\n",
    "                delta = current_text[len(previous_text):]\n",
    "                parser.parse_incremental(delta)\n",
    "                previous_text = current_text\n",
    "\n",
    "        log_entry = await log_streamed_run(agent, result)\n",
    "        save_log(log_entry)\n",
    "\n",
    "\n",
    "    # print(article.format_article())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0cae4",
   "metadata": {},
   "source": [
    "## Building the Streamlit Application\n",
    "\n",
    "Let's now turn this into a Streamlit chat application.\n",
    "\n",
    "My prompt for ChatGPT:\n",
    "\n",
    "```text\n",
    "Create a streamlit chat application that asks the user for input and sends it to the agent.\n",
    "\n",
    "Display the tool calls from the agent as well as the output as it arrives.\n",
    "\n",
    "Here's the current code I have:\n",
    "# insert the tool call callback code\n",
    "# insert the streaming code\n",
    "```\n",
    "\n",
    "[Converstaion with ChatGPT](https://chatgpt.com/share/69049307-ef70-800a-9195-428f0c53e7f0)\n",
    "\n",
    "The resulting Streamlit application provides:\n",
    "\n",
    "- A chat interface for user input\n",
    "- Real-time display of tool calls\n",
    "- Streaming output as the agent generates responses\n",
    "- Proper formatting of the structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1769267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add streamlit\n",
    "!uv run streamlit run ver4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698b883c",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now our application is ready for the next step: collecting logs. The streaming interface provides a much better user experience while maintaining all the functionality of our agent system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
