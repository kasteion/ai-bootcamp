{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7720e1",
   "metadata": {},
   "source": [
    "# Creating a Log Ingestion/Monitoring System with Postgres and Streamlit\n",
    "\n",
    "We have saved logs from our agent interactions. Now let's build a system to consume, analyze, and visualize them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613900cd",
   "metadata": {},
   "source": [
    "## System Architecture Overview\n",
    "\n",
    "Imagine we have a Kafka stream where our app saves the logs. On the other end, we read these logs, analyze them, and create visualizations.\n",
    "\n",
    "We'll build a system with PostgreSQL that loads these logs and displays them. We can also have a judge (without reference) that evaluates the results in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfdd31f",
   "metadata": {},
   "source": [
    "## Creating the Log Processing System\n",
    "\n",
    "Let's start by creating a comprehensive monitoring system.\n",
    "\n",
    "I'll use a coding agent for creating it. Here's the initial prompt I used:\n",
    "\n",
    "```text\n",
    "I want to create a system that monitors the logs in the logs/ directory (make it abstract so I can later replace it with s3, kafka, etc), reads logs, adds \"_\" at the beginning after successfully processing each file and puts the content in postgres \n",
    "\n",
    "use postgres database for storing the data but make it generic (use something like SQLAlchemy)\n",
    "\n",
    "for the logs, extract:\n",
    "\n",
    "- the first message - the user prompt \n",
    "- the instructions\n",
    "- the model\n",
    "- total usage at the end (input, output tokens)\n",
    "\n",
    "in addition I want to run LLM eval on each log record that will add different checks to a different table:\n",
    "\n",
    "class CheckName(str, Enum):\n",
    "    instructions_follow = \"instructions_follow\"\n",
    "    instructions_avoid = \"instructions_avoid\" \n",
    "    answer_clear = \"answer_clear\"\n",
    "    answer_match = \"answer_match\"\n",
    "    answer_citations = \"answer_citations\"\n",
    "    completeness = \"completeness\"\n",
    "    tool_call_search = \"tool_call_search\"\n",
    "\n",
    "also I want to be able to save user feedback: they will inspect the data and say if the answer is good or add comments or reference answers. They should be able to say if it's good (thumbs up) or bad (thumbs down)\n",
    "\n",
    "all the files should be in the \"monitoring\" folder\n",
    "\n",
    "# include json file with the log if you use ChatGPT and all other relevant code \n",
    "```\n",
    "\n",
    "This creates the foundation for our monitoring infrastructure with proper database schema and evaluation framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f3ba8",
   "metadata": {},
   "source": [
    "## Building the Streamlit Dashboard\n",
    "\n",
    "The next step is creating a user interface for viewing and managing the logs.\n",
    "\n",
    "Here's my second prompt:\n",
    "\n",
    "```text\n",
    "create a simple streamlit app for viewing the logs, the evaluation results and adding feedback\n",
    "\n",
    "the streamlit app will only display the items in the database\n",
    "\n",
    "another app will run and periodically check the logs - let's say every 10 seconds\n",
    "\n",
    "let's also add price calculation when ingesting \n",
    "\n",
    "code for that:\n",
    "\n",
    "from genai_prices import Usage, calc_price \n",
    "\n",
    "token_usage = Usage(input_tokens=input_tokens, output_tokens=output_tokens)\n",
    "\n",
    "price_data = calc_price(\n",
    "    token_usage,\n",
    "    provider_id=provider,\n",
    "    model_ref=model\n",
    ")\n",
    "\n",
    "input_cost = price_data.input_price\n",
    "output_cost = price_data.output_price\n",
    "total_cost = price_data.total_price\n",
    "\n",
    "the costs returned as Decimal objects\n",
    "```\n",
    "\n",
    "This creates:\n",
    "\n",
    "- A Streamlit dashboard for viewing logs and evaluation results\n",
    "- A separate polling service that monitors the logs directory (note that in the video the agent created the polling service even without me asking for it, so I don't include that part)\n",
    "- Integrated cost calculation for each interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1b96f7",
   "metadata": {},
   "source": [
    "## Containerization\n",
    "\n",
    "Finally, let's containerize the entire system:\n",
    "\n",
    "let's create a docker compose file with postgres and create instructions for running streamlit app and the poller\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  postgres:\n",
    "    image: postgres:16-alpine\n",
    "    environment:\n",
    "      POSTGRES_DB: monitoring\n",
    "      POSTGRES_USER: monitoring\n",
    "      POSTGRES_PASSWORD: monitoring\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    volumes:\n",
    "      - pgdata:/var/lib/postgresql/data\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB\"]\n",
    "      interval: 5s\n",
    "      timeout: 5s\n",
    "      retries: 10\n",
    "\n",
    "volumes:\n",
    "  pgdata:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d1d06a",
   "metadata": {},
   "source": [
    "## Running the Complete System\n",
    "\n",
    "[code](https://github.com/alexeygrigorev/ai-bootcamp-codespace/tree/main/week4/code/monitoring)\n",
    "\n",
    "Note: the code you generated may be different, so follow the instructions from your coding agent.\n",
    "\n",
    "Let's start PostgreSQL with Docker:\n",
    "\n",
    "```bash\n",
    "docker-compose up postgres\n",
    "```\n",
    "\n",
    "Now start the poller:\n",
    "\n",
    "```bash\n",
    "export DATABASE_URL=postgresql://monitoring:monitoring@localhost:5432/monitoring\n",
    "uv run python -m monitoring.runner --watch --debug\n",
    "```\n",
    "\n",
    "Start the Streamlit application:\n",
    "\n",
    "```bash\n",
    "PYTHONPATH='.' uv run streamlit run monitoring/app.py\n",
    "```\n",
    "\n",
    "We add PYTHONPATH='.' because otherwise Python won't be able to recongize monitoring as a module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b26df",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- Implement better UI: show the information in a table, add filters\n",
    "- Implement LLM as a Judge approach for checks\n",
    "- Create a gold standard dataset based on the actual user interactions\n",
    "- Implement a Grafana dashboard (next lesson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38425bcd",
   "metadata": {},
   "source": [
    "## Key System Components\n",
    "\n",
    "The complete monitoring system includes:\n",
    "\n",
    "- Log Ingestion: Automatically processes new log files and extracts key metrics\n",
    "- Cost Tracking: Calculates costs for each interaction using provider-specific pricing\n",
    "- LLM Evaluation: Automated quality assessment using predefined criteria\n",
    "- User Feedback: Interface for manual review and rating of agent responses\n",
    "- Real-time Dashboard: Streamlit interface for monitoring and analysis\n",
    "\n",
    "This monitoring system provides visibility into agent performance, costs, and quality.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
